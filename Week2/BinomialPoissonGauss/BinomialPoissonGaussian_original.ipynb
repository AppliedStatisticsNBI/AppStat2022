{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binomial, Poisson and Gaussian distributions\n",
    "\n",
    "Python notebook for illustrating the Binomial, Poisson and Gaussian distributions and how they in certain limits converge towards each other (and in the end into the Gaussian). The notebook also illustrates simple fitting.\n",
    "\n",
    "## References:\n",
    "- Barlow: Chapter 3\n",
    "- Cowan: Chapter 2\n",
    "- Particle Data Group: __[\"Probability theorem and distributions\"](https://pdg.lbl.gov/2020/reviews/rpp2020-rev-probability.pdf)__\n",
    "\n",
    "## Author(s), contact(s), and dates:\n",
    "- Author: Troels C. Petersen (NBI)\n",
    "- Email:  petersen@nbi.dk\n",
    "- Date:   23rd of November 2022\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                     # Matlab like syntax for linear algebra and functions\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt                        # Plots and figures like you know them from Matlab\n",
    "from iminuit import Minuit                             # The actual fitting tool, better than scipy's\n",
    "import sys                                             # Modules to see files and folders in directories\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import binom, poisson, norm           # Functions from SciPy Stats..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `SciPy Stats` has nearly every conceivable function implemented:\n",
    "__[\"SciPy Stats functions\"](https://docs.scipy.org/doc/scipy/reference/stats.html)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../External_Functions')\n",
    "from ExternalFunctions import Chi2Regression\n",
    "from ExternalFunctions import nice_string_output, add_text_to_ax   # Useful functions to print fit results on figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up the parameters for the program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General settings:\n",
    "r = np.random                       # Random generator\n",
    "r.seed(42)                          # Fixed order of random numbers\n",
    "\n",
    "save_plots = False\n",
    "verbose = True\n",
    "N_verbose = 10\n",
    "\n",
    "# Set plotting parameters:\n",
    "mpl.rcParams['font.size'] = 18      # Set the general plotting font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting PDFs:\n",
    "\n",
    "First, we want to have a look at the three PDFs (Binomial, Poisson, and Gaussian), and compare them given \"the same\" parameters. Of course we can't give the same input parameters, but at least we can require that they have the same mean and widths... Almost - one can not force the width of the Poisson to match that of the Binomial, once the mean is matched. The Gaussian will then have to choose between these two slightly different widths!\n",
    "\n",
    "### Problem parameters:\n",
    "* The Binomial PDF needs two parameters: Number of trials (n) and probability of succes (p).\n",
    "* The Poisson PDF needs one parameter:  The expected number (lambda - but in Python we write it \"Lambda\" or \"lamp\", as \"lambda\" is reserved!).\n",
    "* The Gaussian PDF needs two parameters: Mean (mu) and width (sigma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_binomial_pmf(x, n, p):\n",
    "    return binom.pmf(x, n, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_poisson_pmf(x, lamb):\n",
    "    return poisson.pmf(x, lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def func_gaussian_pdf(x, mu, sigma) :\n",
    "    return norm.pdf(x, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Range of outcome:\n",
    "xmin = -0.5\n",
    "xmax = 13.5\n",
    "\n",
    "# Function parameters:\n",
    "# Binomial:\n",
    "n = 20\n",
    "p = 0.2\n",
    "# Poisson:\n",
    "Lambda = n * p               # We choose this, as this is the expected number of successes.\n",
    "# Gaussian:\n",
    "mu = Lambda                  # Same here - the central value is n*p.\n",
    "sigma = np.sqrt(n*p*(1-p))   # For a Binomial process, the variance is n*p*(1-p)\n",
    "sigma = np.sqrt(n*p)         # Alternatively, one can use the Poisson width.\n",
    "                             # Note how for small values of p, these expressions are essentially the same!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis = np.linspace(xmin, xmax, 1000)\n",
    "yaxis_binom = func_binomial_pmf(np.floor(xaxis+0.5), n, p)      # np.floor: See below\n",
    "yaxis_poiss = func_poisson_pmf(np.floor(xaxis+0.5), Lambda)     # np.floor: See below\n",
    "yaxis_gauss = func_gaussian_pdf(xaxis, n*p, np.sqrt(n*p*(1-p)))\n",
    "\n",
    "# Note that the np.floor function takes the integer/rounded (towards zero) value of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig0, ax0 = plt.subplots(figsize=(16, 8))\n",
    "ax0.plot(xaxis, yaxis_binom, '-', label=f'Binomial with n={n:2d} and p={p:.3f}')\n",
    "ax0.plot(xaxis, yaxis_poiss, '-', label=f'Poisson with lambda={Lambda:.2f}')\n",
    "ax0.plot(xaxis, yaxis_gauss, '-', label=f'Gaussian with mu={mu:.2f} and sigma={sigma:.2f}')\n",
    "ax0.set(xlim=(xmin, xmax),\n",
    "        title='Probability for Binomial and Gaussian', \n",
    "        xlabel='x', \n",
    "        ylabel='Probability')\n",
    "ax0.set_yscale('log')\n",
    "ax0.set_ylim(1e-4, 1.0)\n",
    "ax0.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looping over processes:\n",
    "In the following we simulate a Binomial/Poisson process with given parameters, i.e. number of trials and probability of success. For the Poisson, these can not be specified, but the resulting expected number is naturally lambda = n * p.\n",
    "\n",
    "After having simulated the process, we fit the result with the three distributions in question, and test to what extend they match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters:\n",
    "N_experiments = 1000              # Number of simulations/experiments to perform\n",
    "\n",
    "N_trials = n                      # Number of trials in each experiment (taken from above!)\n",
    "p_success = p                     # Chance of succes in each trial (taken from above!)\n",
    "Lambda = N_trials * p_success     # This is the mean and the one parameter by which the Poisson is defined!\n",
    "\n",
    "print(f\"  With N_trials = {N_trials:d} and p_success = {p_success:.4f}, the average number of successes is lambda = {Lambda:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_n_success = np.zeros(N_experiments)\n",
    "\n",
    "# Run the experiments, and fill the histogram from above:\n",
    "for iexp in range(N_experiments): \n",
    "    \n",
    "    # Simulating process defined:\n",
    "    n_success = 0\n",
    "    for i in range(N_trials): \n",
    "        x = r.uniform()\n",
    "        if (x < p_success): \n",
    "            n_success += 1\n",
    "\n",
    "    # Record result:\n",
    "    if (verbose and iexp < N_verbose): \n",
    "        print(f\"n_success: {n_success:4d}\")\n",
    "        \n",
    "    # Save Result\n",
    "    all_n_success[iexp] = n_success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot result:\n",
    "\n",
    "Define a histogram with the \"data\" (note and think about the binning!). Also, ask yourself what uncertainty to assign to each bin?<br>\n",
    "The line of thinking should be: \"There are many possibilities of ending up in a specific bin, but the probability of doing so is each low\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts, bin_edges = np.histogram(all_n_success, bins=N_trials+1, range=(-0.5, N_trials+0.5))\n",
    "bin_centers = (bin_edges[1:] + bin_edges[:-1])/2\n",
    "s_counts = np.sqrt(counts)                         # NOTE: We (naturally) assume that the bin count is Poisson distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remove any bins, which don't have any counts in them (for Chi2 fitting):\n",
    "x = bin_centers[counts>0]\n",
    "y = counts[counts>0]\n",
    "sy = s_counts[counts>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "ax.errorbar(x, y, yerr=sy, xerr=0.5, label='Distribution of nSuccesses', fmt='.k',  ecolor='k', elinewidth=1, capsize=1, capthick=1)\n",
    "ax.set(xlim=(xmin, xmax), ylim=(0, 1.2*np.max(y)), xlabel='Number of successes', ylabel='Frequency');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting with a Binomial:\n",
    "\n",
    "First define the (fitting) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_binomial(x, N, n, p):\n",
    "    return N * binom.pmf(x, n, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then fit it with a $\\chi^2$-fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Minuit.print_level = 1\n",
    "\n",
    "chi2_bin = Chi2Regression(func_binomial, x, y, sy)\n",
    "chi2_bin.errordef = 1\n",
    "minuit_bin = Minuit(chi2_bin, N=N_experiments, n=N_trials, p=p_success) #   \n",
    "minuit_bin.migrad()          # Perform the actual fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot it on the figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chi2_bin = minuit_bin.fval\n",
    "Ndof_bin = len(x) - 3        # 3 parameters in fit\n",
    "Prob_bin = stats.chi2.sf(Chi2_bin, Ndof_bin)\n",
    "\n",
    "xaxis = np.linspace(-0.5, N_trials+0.5, 1000)                  # This way we include all possibilties!\n",
    "yaxis = func_binomial(np.floor(xaxis+0.5), *minuit_bin.values[:])\n",
    "ax.plot(xaxis, yaxis, '-', label=f'Binomial fit: p(Chi2={Chi2_bin:.1f},Ndof={Ndof_bin:d}) = {Prob_bin:.3f}')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting with a Poisson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_poisson(x, N, mu) :\n",
    "    return N * poisson.pmf(x, mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_poisson = Chi2Regression(func_poisson, x, y, sy)\n",
    "chi2_poisson.errordef = 1\n",
    "minuit_poisson = Minuit(chi2_poisson, N=N_experiments, mu=Lambda) #   \n",
    "minuit_poisson.migrad();           # Perform the actual fit (without printing)\n",
    "Chi2_poi = minuit_poisson.fval\n",
    "Ndof_poi = len(x) - 2              # 2 parameters in fit\n",
    "Prob_poi = stats.chi2.sf(Chi2_poi, Ndof_poi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaxis = func_poisson(np.floor(xaxis+0.5), *minuit_poisson.values[:])\n",
    "ax.plot(xaxis, yaxis, '-', label=f'Poisson fit: p(Chi2={Chi2_poi:.1f},Ndof={Ndof_poi:d}) = {Prob_poi:.3f}')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting with a Gaussian:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_gaussian(x, N, mu, sigma) :\n",
    "    return N * norm.pdf(x, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_gaussian = Chi2Regression(func_gaussian, x, y, sy)\n",
    "chi2_gaussian.errordef = 1\n",
    "minuit_gaussian = Minuit(chi2_gaussian, N=N_experiments, mu=Lambda, sigma=np.sqrt(Lambda)) #   \n",
    "minuit_gaussian.migrad();       # Perform the actual fit\n",
    "Chi2_gau = minuit_gaussian.fval\n",
    "Ndof_gau = len(x) - 3           # 3 parameters in fit\n",
    "Prob_gau = stats.chi2.sf(Chi2_gau, Ndof_gau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaxis = func_gaussian(xaxis, *minuit_gaussian.values[:])\n",
    "ax.plot(xaxis, yaxis, '-', label=f'Gaussian fit: p(Chi2={Chi2_gau:.1f},Ndof={Ndof_gau:d}) = {Prob_gau:.3f}')\n",
    "ax.legend()\n",
    "fig.tight_layout()\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And save the figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if save_plots: \n",
    "    fig.savefig(\"BinomialPoissonGaussian.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of Binomial $\\chi^2$-value:\n",
    "\n",
    "In this part of the exercise, you are asked to calculate the ChiSquare value yourself, in order to ensure that you understand exactly what is going on!\n",
    "\n",
    "Above, we have (using Minuit) *fitted* the distribution, but as we know the initial values, I would like you to calculate the $\\chi^2$-value between the data and the binomial they were generated from, i.e. with NO free parameters.\n",
    "\n",
    "I suggest you use Pearson's $\\chi^2$, and require `N_obs` and/or `N_exp` > e.g. 0.1. Remember that your choice should ensure, that there is no division by zero (which is a cardinal sin in programming)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_bins = len(x)                # Just to know how many bins to loop over\n",
    "chi2_bino = 0.0                # This you'll add to\n",
    "N_dof = 0                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for N_obs, x_i in zip(y, x):\n",
    "    N_exp = func_binomial(x_i, N_experiments, N_trials, p_success)\n",
    "    if (N_obs > 0) :\n",
    "        chi2_bino += 0.0       # Write the expression yourself!\n",
    "\n",
    "# Also calculate Ndof and Prob:\n",
    "Ndof_bino = 1                  # Think about/write the number of degrees of freedom given no free parameters!\n",
    "Prob_bino = stats.chi2.sf(chi2_bino, Ndof_bino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "print(f\"Just a test printout, change to match your own results! \\n\")\n",
    "print(f\"Binomial:   chi2 = {9999:.2f}   N_dof = {9999:d}   Prob = {9999:6.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "\n",
    "# Questions:\n",
    "\n",
    "Important: Make sure you understand what process yields a Binomial, a Poisson and a Gaussian distribution. Without this knowledge, this exercise and a large fraction of the course will be lost on you!\n",
    "\n",
    "1. Plot a Binomial ($N=20$, $p=0.2$), Poisson ($\\lambda = 4$), and Gaussian ($\\mu=4$, $\\sigma=\\sqrt{4}$), i.e. same means and widths. Which distribution has the longest tail towards high values? And which one has the longest tail the other way? Does this pattern depend on the parameters (given same means and widths)? Play around with the settings (remember also to change the scale (use log) of the plot accordingly), and gain your own experience. And most importantly perhaps, in what limits do they start looking like each other?\n",
    "\n",
    "2. Producing binomially distributed numbers (using the parameters `N_experiments=1000`, `N_trials=10` and `p_success=0.2`), do $\\chi^2$ fits of the resulting distribution with a Binomial, a Poisson, and a Gaussian distribution. Do you get acceptable fit probabilities with all of these? If not, investigate for what choice of parameters you do.\n",
    "\n",
    "3. Calculate the $\\chi^2$ between the data and the original Binomial distribution (which the data is generated from). Since you are not fitting anything, what is the number of degrees of freedom? Does it give a reasonable $\\chi^2$-probability?\n",
    "\n",
    "4. In all of the above $\\chi^2$ fits, we have _assumed_ that the uncertainty on the count in each bin is Gaussianly distributed! Ask yourself to what extend this requirement is fulfilled? Does changing the parameters (`N_experiments`, `N_trials` and `p_success`) \"help\" fulfilling this requirement, and if so, which and how?\n",
    "\n",
    "### Advanced questions:\n",
    "\n",
    "5. Using `N_experiments=1000`, `N_trials=1000` and `p_success=1/60`, is the skewness consistent with zero (as the Gaussian should have)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning points:\n",
    "\n",
    "Generally, you should understand the concept of a PDF, and that there are many such, though in this course we only consider 10 or so. Some are *continuous* (e.g. exponential and Gaussian) and some are *discrete* (e.g. Binomial and Poisson).\n",
    "\n",
    "In this exercise, you should have learned:\n",
    "1. What the conditions leading to a Binomial and a Poisson distribution are.\n",
    "2. In what limit of $N_{trials}$ and $p_{succes}$ the Binomial converges towards the Poisson.\n",
    "3. That in the limit of $N_{trials} \\times p_{succes} \\to \\infty$ and $\\lambda \\to \\infty$, the two distributions become Gaussian (though discrete).\n",
    "4. **That the uncertainty on a Poisson number is the square root of that number**.\n",
    "\n",
    "One consequence of 4), is that we choose number of counts in a bin $N$ to have $\\sqrt{N}$ as uncertainty. It should be noted, that for low $N$, the uncertainty is not very Gaussian.\n",
    "\n",
    "You should also have learned how to choose binning when making a histogram of integers. "
   ]
  }
 ],
 "metadata": {
  "executable": "/usr/bin/env python",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "main_language": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
